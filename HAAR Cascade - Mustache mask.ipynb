{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and configure Haar Cascade Classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2 # OpenCV Library\n",
    "\n",
    "# location of OpenCV Haar Cascade Classifiers:\n",
    "baseCascadePath = \"/usr/local/share/OpenCV/haarcascades/\"\n",
    "\n",
    "# xml files describing our haar cascade classifiers\n",
    "faceCascadeFilePath = baseCascadePath + \"haarcascade_frontalface_default.xml\"\n",
    "noseCascadeFilePath = baseCascadePath + \"haarcascade_mcs_nose.xml\"\n",
    " \n",
    "# build our cv2 Cascade Classifiers\n",
    "faceCascade = cv2.CascadeClassifier(faceCascadeFilePath)\n",
    "noseCascade = cv2.CascadeClassifier(noseCascadeFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\cv\\\\opencv\\\\Scripts\\\\Notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load and configure mustache (.png with alpha transparency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9eaede57dcf2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load our overlay image: mustache.png\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimgMustache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mustache.png'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create the mask for the mustache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0morig_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgMustache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    " # Load our overlay image: mustache.png\n",
    "imgMustache = cv2.imread('mustache.png',-1)\n",
    " \n",
    "# Create the mask for the mustache\n",
    "orig_mask = imgMustache[:,:,3]\n",
    " \n",
    "# Create the inverted mask for the mustache\n",
    "orig_mask_inv = cv2.bitwise_not(orig_mask)\n",
    " \n",
    "# Convert mustache image to BGR\n",
    "# and save the original image size (used later when re-sizing the image)\n",
    "imgMustache = imgMustache[:,:,0:3]\n",
    "origMustacheHeight, origMustacheWidth = imgMustache.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show me!\n",
    "cv2.imshow('must', imgMustache)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main program loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-9294f89d0be8>, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-9294f89d0be8>\"\u001b[1;36m, line \u001b[1;32m29\u001b[0m\n\u001b[1;33m    nose = noseCascade.detectMultiScale(roi_gray) 0\u001b[0m\n\u001b[1;37m                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# collect video input from first webcam on system\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "video_capture.open(0)\n",
    "    \n",
    "while True:\n",
    "    # Capture video feed\n",
    "    ret, frame = video_capture.read()\n",
    " \n",
    "    # Create greyscale image from the video feed\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    # Detect faces in input video stream\n",
    "    faces = faceCascade.detectMultiScale(gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE)\n",
    " \n",
    "   # Iterate over each face found\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Un-comment the next line for debug (draw box around all faces)\n",
    "        # face = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    " \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    " \n",
    "        # Detect a nose within the region bounded by each face (the ROI)\n",
    "        nose = noseCascade.detectMultiScale(roi_gray) 0\n",
    " \n",
    "        for (nx,ny,nw,nh) in nose:\n",
    "            # Un-comment the next line for debug (draw box around the nose)\n",
    "            #cv2.rectangle(roi_color,(nx,ny),(nx+nw,ny+nh),(255,0,0),2)\n",
    " \n",
    "            # The mustache should be three times the width of the nose\n",
    "            mustacheWidth =  3 * nw\n",
    "            mustacheHeight = mustacheWidth * origMustacheHeight / origMustacheWidth\n",
    " \n",
    "            # Center the mustache on the bottom of the nose\n",
    "            x1 = nx - (mustacheWidth/4)\n",
    "            x2 = nx + nw + (mustacheWidth/4)\n",
    "            y1 = ny + nh - (mustacheHeight/2)\n",
    "            y2 = ny + nh + (mustacheHeight/2)\n",
    " \n",
    "            # Check for clipping\n",
    "            if x1 < 0:\n",
    "                x1 = 0\n",
    "            if y1 < 0:\n",
    "                y1 = 0\n",
    "            if x2 > w:\n",
    "                x2 = w\n",
    "            if y2 > h:\n",
    "                y2 = h\n",
    " \n",
    "            # Re-calculate the width and height of the mustache image\n",
    "            mustacheWidth = x2 - x1\n",
    "            mustacheHeight = y2 - y1\n",
    " \n",
    "            # Re-size the original image and the masks to the mustache sizes\n",
    "            # calcualted above\n",
    "            mustache = cv2.resize(imgMustache, (mustacheWidth,mustacheHeight), interpolation = cv2.INTER_AREA)\n",
    "            mask = cv2.resize(orig_mask, (mustacheWidth,mustacheHeight), interpolation = cv2.INTER_AREA)\n",
    "            mask_inv = cv2.resize(orig_mask_inv, (mustacheWidth,mustacheHeight), interpolation = cv2.INTER_AREA)\n",
    " \n",
    "            # take ROI for mustache from background equal to size of mustache image\n",
    "            roi = roi_color[y1:y2, x1:x2]\n",
    " \n",
    "            # roi_bg contains the original image only where the mustache is not\n",
    "            # in the region that is the size of the mustache.\n",
    "            roi_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    " \n",
    "            # roi_fg contains the image of the mustache only where the mustache is\n",
    "            roi_fg = cv2.bitwise_and(mustache,mustache,mask = mask)\n",
    " \n",
    "            # join the roi_bg and roi_fg\n",
    "            dst = cv2.add(roi_bg,roi_fg)\n",
    " \n",
    "            # place the joined image, saved to dst back over the original image\n",
    "            roi_color[y1:y2, x1:x2] = dst\n",
    " \n",
    "            break\n",
    " \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    " \n",
    "    # press any key to exit\n",
    "    # NOTE;  x86 systems may need to remove: \" 0xFF == ord('q')\"\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
